% !TeX encoding = UTF-8
% !TeX spellcheck = en_US
\documentclass{article}

\usepackage{amsmath}
\usepackage{amsfonts}

\newcommand{\xor}{\oplus}
\newcommand{\djb}{\mathrm{djb}}
\newcommand{\muladd}{\mathrm{muladd}}

\newcommand{\OO}{\mathcal{O}}

\newcommand{\Nats}{\mathbb{N}}

\title{Efficient Minimal Perfect Order-Preserving Hash Functions}
\author{Sven KÃ¶hler}

\begin{document}

\maketitle

\begin{abstract}
The goal is to write a generator for minimal perfect hash functions.
The target are embedded systems, so the hash function will be generated
with a C++ program during the build process. The generated hash functions
are stores as JSON objects and then converted to C code (or other languages)
using a another utility.

The hash functions must focus on space and time efficiency on embedded systems 
like ARM microcontrollers.
\end{abstract}

\section{Perfect Minimal Order-Preserving Hash Functions}

Hash functions map a potentially infinite set of inputs
(e.g., the set of all strings) 
to a finite set of outputs.
Hence there will be collisions.

Let $X$ be a finite subset of inputs, $n=|X|$, and $Y$ the output domain
of the hash function.
A hash function is called \emph{perfect}, if it does not
produce collisions for any two inputs in $X$. 
A perfect hash function is \emph{minimal}, if $|Y|=|X|$,
i.e., a minimal perfect hash function is a bijection
between the sets $X$ and $Y$. 
Furthermore, a hash function is order-preserving,
if it holds $h(x_1) > h(x_2)$ for any two inputs
$x_1, x_2\in X$ with $x_1 > x_2$.

Consider the sequence $x_0, x_1, \ldots, x_{n-1}$ that
contains every input in $X$ exactly once in ascending
order. A minimal order-preserving hash function with
output domain $Y=[0,n-1]$ will map every input $x_i$
to the value $i$, i.e., the position in the sequence.

\section{Compression}

Consider a perfect hash function with output domain $[0,n'-1]$ where $n'>n$. 
Then this range can compressed to $[0,n-1]$ as follows:
Store a mask with $n'$ bits. The mask contains one bit for each value in the 
output domain $[0,n'-1]$: a $1$ for each used value and a $0$ for each unused 
value. Then we store the number of used values in the interval $[0,32k-1]$ with
$k\in\Nats$.


\section{Construction}

\subsection{CHM Algorithm}
In this section we construct a hash function
$h_p$ which assigns chosen values to every $x\in X$.

Let $h_1$ and $h_2$ denote two hash functions
with the output domain $[0,m-1]$ for $m \ge n$.
Let $G=(V,E)$ with $V=[0,m-1]$ and
$E=\{ e_x \mid x\in X \}$.
The edge $e_x$ connects nodes $h_1(x)$ and $h_2(x)$.

If the graph $G$ has no loops, no parallels, and no cycles,
then $G$ is a forest. We construct a mapping $w$, which assigns
a value to each node $v\in V$.
For each tree in the forest we pick a root,
assign the value $0$ to the root and perform a BFS starting at the root.
Consider an edge $e_x=[u,v]$ used by the BFS. Let $u$ be the node
already discovered and $v$ an undiscovered node.
Then we set $w(v)=w(u) \xor h_p(x)$.

The desired hash function then is $h_p(x)= w(h_1(x)) \xor w(h_2(x))$.
The storage complexity is $\OO(m)$ plus any storage required
for hash functions $h_1$ and $h_2$.

\subsubsection{Optimizations}
It is best to use union find to detect cycles, parallels, and loops in an early 
stage of building the graphs. We build the actual graph only if union find 
confirms that it will be acyclic.

\subsubsection{Evaluation}
The generated hash functions are minimal and order preserving.
In fact, the value assigned to each key can be freely chosen.
This is the main advantage over the other algorithms.


\subsection{BMZ Algorithm}

The BMZ algorithm is an extension of the CHM algorithm. The graph is in fact 
allowed to be cyclic. We graph can be viewed as connected components with trees 
attached to them. The majority of nodes must be in those trees. 
Loops are resolved in an ad-hoc fashion.

\subsubsection{Optimizations}
It would be nice to keep track of the number of nodes in the trees on the fly 
to detect invalid graphs early. This has not been tested yet.

\subsubsection{Evaluation}
The generated hash functions are minimal, but not order preserving.
Since cycles are allowed in the graph, the hash functions take up less space 
than the ones generated by the CHM algorithm. However, the BDZ algorithm 
generates much more compact functions with little extra computational overhead.


\subsection{BDZ Algorithm}

Given an integer parameter $r\ge 2$, the BDZ builds an $r$-partite hypergraph.
Each edge of the hypergraph connects $r$ nodes, one from each of the $r$ parts.
The graph is considered acyclic, if the following algorithm removes all edges 
of the graph:
\begin{itemize}
\item remove all edges that are incidents to nodes of degree 1
\item update the degree of all nodes
\item repeat
\end{itemize}

The value assigned to each edge (and thus each key) is the index of the node
with degree one at the time of removal.

\subsubsection{Optimizations}
For $r=2$, it is best to use union find to detect cycles and parallels 
in an early stage of building the graphs. We build the actual graph only if 
union find confirms that the graph will be acyclic.

\subsubsection{Evaluation}
The generated hash function are neither minimal nor order preserving, but can 
be compressed.
The storage required for both the hash function and the compression table is 
much less than the BDZ or CHM algorithm, even if $r=2$.
Also, using bipartite graphs seems to have a slight advantage over using 
general graphs. The impossibility of loops might be a beneficial factor which
makes the bipartite graphs smaller than the general used by the CHM algorithm.

The bipartite graph can also be used to generate a minimal order preserving 
perfect hash function. However, the storage complexity would increase.


\section{Suitable Hash Functions}

Clearly hash functions $h_1$ and $h_2$ must not be equal.
The hash functions must return different values for the
same input and the induced graph must be acyclic.

The hash functions are chosen at random. This section
discusses techniques to construct random hash functions.

Let $c=(c_1, c_2, \ldots, c_n)$ be a character sequence.

\subsection{Mult+Add}

A simple hash function used in the original paper is the following:

\begin{align*}
\muladd(c) &= \sum_{i=1}^n t_i \cdot c_i \mod 2^{32}
\end{align*}

where $t$ is a table with random coefficient.

The space complexity for storing the hash function is $\OO(n)$ where
$n$ is the longest input in $X$.


\subsection{DJB}

The DJB hash function is defined as follows:
\begin{align*}
\djb(c) &= (((5381\cdot 33+c_1)\cdot 33+c_2)\cdot 33+c_3)\cdot 33+c_4 \ldots\\
    &= 5381\cdot 33^n + \sum_{i=1}^n 33^{n-i}\cdot c_i \mod 2^{32}
\end{align*}
where $5381$ is the seed.
Consider a table $t$ with random values.
One can replace $c_i$ with $c'_i=c_i+t_i$ or $c''_i=c_i\xor t_i$.

If the length $n$ is constant, then using $c'$ basically just changes the seed.

Using $c''$ may not always work. Consider $n=1$ and assume that the word list
covers the entire alphabet. Then, for every choice of $t$, there will always
be two words that create a cycle. However, this seems to work good in practice
when the words only consist of letters.

The space complexity for storing the hash function is $\OO(n)$ where
$n$ is the longest input in $X$.

\subsection{Jenkins One-at-a-Time}

\subsection{Jenkins Lookup2}

\subsection{Jenkins Lookup3}

\section{References}

An Optimal algorithm for generating minimal perfect hash functions.
Z. J. Czech, G. Havas and B.S. Majewski.
http://cmph.sourceforge.net/papers/chm92.pdf

\end{document}
